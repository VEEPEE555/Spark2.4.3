{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyspark.sql.session.SparkSession object at 0x7f624824ac88>\n"
     ]
    }
   ],
   "source": [
    "#Invoke/initialize the spark session ( point of entry into the Sparkverse)\n",
    "from pyspark.sql import *\n",
    "spark = SparkSession \\\n",
    ".builder.master(\"local\") \\\n",
    ".appName(\"Word Count\") \\\n",
    ".getOrCreate()\n",
    "\n",
    "print (spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.RDD"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading a file to spark creating an RDD (orders data)\n",
    "ordersRDD = spark.sparkContext.textFile('/home/veepee555/retail_db/orders')\n",
    "type(ordersRDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.RDD"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading a file to spark creating an RDD (order items data)\n",
    "order_itemsRDD = spark.sparkContext.textFile('/home/veepee555/retail_db/order_items')\n",
    "\n",
    "type(order_itemsRDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,2013-07-25 00:00:00.0,11599,CLOSED\n",
      "2,2013-07-25 00:00:00.0,256,PENDING_PAYMENT\n",
      "3,2013-07-25 00:00:00.0,12111,COMPLETE\n",
      "4,2013-07-25 00:00:00.0,8827,CLOSED\n",
      "5,2013-07-25 00:00:00.0,11318,COMPLETE\n",
      "6,2013-07-25 00:00:00.0,7130,COMPLETE\n",
      "7,2013-07-25 00:00:00.0,4530,COMPLETE\n",
      "8,2013-07-25 00:00:00.0,2911,PROCESSING\n",
      "9,2013-07-25 00:00:00.0,5657,PENDING_PAYMENT\n",
      "10,2013-07-25 00:00:00.0,5648,PENDING_PAYMENT\n"
     ]
    }
   ],
   "source": [
    "#Display RDD data , take(10)\n",
    "for rec in ordersRDD.take(10):\n",
    "    print (rec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,1,957,1,299.98,299.98\n",
      "2,2,1073,1,199.99,199.99\n",
      "3,2,502,5,250.0,50.0\n",
      "4,2,403,1,129.99,129.99\n",
      "5,4,897,2,49.98,24.99\n",
      "6,4,365,5,299.95,59.99\n",
      "7,4,502,3,150.0,50.0\n",
      "8,4,1014,4,199.92,49.98\n",
      "9,5,957,1,299.98,299.98\n",
      "10,5,365,5,299.95,59.99\n"
     ]
    }
   ],
   "source": [
    "#Display RDD data , take(10)\n",
    "for rec in order_itemsRDD.take(10):\n",
    "    print (rec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RDD data can be saved as a file with compression \n",
    "path='/home/veepee555/ordersRDDCompressed'\n",
    "codec = \"org.apache.hadoop.io.compress.GzipCodec\"\n",
    "ordersRDD.saveAsTextFile(path,codec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 464\r\n",
      "-rw-r--r-- 1 veepee555 veepee555 471106 Jul 20 03:18 part-00000.gz\r\n",
      "-rw-r--r-- 1 veepee555 veepee555      0 Jul 20 03:18 _SUCCESS\r\n"
     ]
    }
   ],
   "source": [
    "# to check if the file was infact save and also compressed with gzip codec\n",
    "!ls -ltr /home/veepee555/ordersRDDCompressed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('', 1352)\n",
      "('Cookie', 1)\n",
      "('Notice', 1)\n",
      "('By', 1)\n",
      "('using', 1)\n",
      "('this', 3)\n",
      "('site,', 1)\n",
      "('you', 3)\n",
      "('agree', 1)\n",
      "('to', 38)\n"
     ]
    }
   ],
   "source": [
    "# Developing word count program\n",
    "# Create a file and type few lines and save it as wordcount.txt  \n",
    "\n",
    "dataRDD = spark.sparkContext.textFile('/home/veepee555/Downloads/data-master/wordcount.txt')\n",
    "dataRDDflatmapped=dataRDD.flatMap(lambda x: x.split(\" \"))\n",
    "dataRDDMap = dataRDDflatmapped.map(lambda x: (x, 1))\n",
    "dataReduceByKey = dataRDDMap.reduceByKey(lambda x,y: x + y)\n",
    "for rec in dataReduceByKey.take(10):\n",
    "    print (rec)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('2013-07-25 00:00:00.0', 199.99)\n",
      "('2013-07-25 00:00:00.0', 250.0)\n",
      "('2013-07-25 00:00:00.0', 129.99)\n",
      "('2013-07-25 00:00:00.0', 49.98)\n",
      "('2013-07-25 00:00:00.0', 299.95)\n",
      "('2013-07-25 00:00:00.0', 150.0)\n",
      "('2013-07-25 00:00:00.0', 199.92)\n",
      "('2013-07-25 00:00:00.0', 179.97)\n",
      "('2013-07-25 00:00:00.0', 299.95)\n",
      "('2013-07-25 00:00:00.0', 199.92)\n"
     ]
    }
   ],
   "source": [
    "# Join disparate datasets together using PySpark\n",
    "\n",
    "# Problem statement, get the revenue from order_items on daily basis\n",
    "\n",
    "#order_item_id int,\n",
    "#order_item_order_id int,\n",
    "#order_item_product_id int,\n",
    "#order_item_quantity int,\n",
    "#order_item_subtotal float,\n",
    "#order_item_product_price float\n",
    "\n",
    "#order_id int,\n",
    "#order_date string,\n",
    "#order_customer_id int,\n",
    "#order_status string\n",
    "#(Both RDD element have the above structures)\n",
    "\n",
    "\n",
    "ordersRDD = spark.sparkContext.textFile('/home/veepee555/retail_db/orders')\n",
    "order_itemsRDD = spark.sparkContext.textFile('/home/veepee555/retail_db/order_items')\n",
    "\n",
    "\n",
    "ordersParsedRDD = ordersRDD.map(lambda rec: (int(rec.split(\",\")[0]), rec))\n",
    "orderItemsParsedRDD = order_itemsRDD.map(lambda rec: (int(rec.split(\",\")[1]),rec))\n",
    "\n",
    "\n",
    "ordersJoinOrderItems = orderItemsParsedRDD.join(ordersParsedRDD)\n",
    "\n",
    "revenuePerOrderPerDay = ordersJoinOrderItems.map(lambda t: (t[1][1].split(\",\")[1], float(t[1][0].split(\",\")[4])))\n",
    "\n",
    "for rec in revenuePerOrderPerDay.take(10):\n",
    "    print (rec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('2013-07-25 00:00:00.0', 199.99)\n",
      "('2013-07-25 00:00:00.0', 250.0)\n",
      "('2013-07-25 00:00:00.0', 129.99)\n",
      "('2013-07-25 00:00:00.0', 49.98)\n",
      "('2013-07-25 00:00:00.0', 299.95)\n",
      "('2013-07-25 00:00:00.0', 150.0)\n",
      "('2013-07-25 00:00:00.0', 199.92)\n",
      "('2013-07-25 00:00:00.0', 179.97)\n",
      "('2013-07-25 00:00:00.0', 299.95)\n",
      "('2013-07-25 00:00:00.0', 199.92)\n"
     ]
    }
   ],
   "source": [
    "# Get order count per day\n",
    "ordersRDD = spark.sparkContext.textFile('/home/veepee555/retail_db/orders')\n",
    "ordersPerDay = ordersJoinOrderItems.map(lambda rec: rec[1][1].split(\",\")[1] + \",\" + str(rec[0])).distinct()\n",
    "ordersPerDayParsedRDD = ordersPerDay.map(lambda rec: (rec.split(\",\")[0], 1))\n",
    "totalOrdersPerDay = ordersPerDayParsedRDD.reduceByKey(lambda x, y: x + y)\n",
    "for rec in revenuePerOrderPerDay.take(10):\n",
    "    print (rec)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
